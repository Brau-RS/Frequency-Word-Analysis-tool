{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389a0141-b28e-4bb1-aa17-b705146f664a",
   "metadata": {},
   "source": [
    "## Frequency word analysis code\n",
    "This code is used to analyze how frequently words appear in an inquiry in a database like PubMed, Web of Science, Embase, ScienceDirect etc. \n",
    "\n",
    "Frequency word analysis can help to identify hot topics, relevant keywords, synonyms and frequent ortographical mistakes. \n",
    "\n",
    "If used qualitatively, results can be used to broaden a search scope and start or refine a search equation. \n",
    "\n",
    "If used quantitatively, it can be used to analyze a big group of results or, if combined with a time-restricted search, it can help to identify tendecy changes within topics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212e365-9821-48aa-937b-9741eab16a53",
   "metadata": {},
   "source": [
    "### 1. Identify the working directory\n",
    "The working directory is the place in the computer where your files are stored.\n",
    "To find it, you can right-click on the file that you want to open and select \"properties\". Copy-paste the location of the file starting with \"C:\\\\\"\n",
    "Do not include the name of the file, only the name of the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf332e4f-6f9c-4fcb-944a-b7d71d029786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braus\\OneDrive\\Documentos\\Escuela\\Internship\\Literature\\SearchEq\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\Braus\\OneDrive\\Documentos\\Escuela\\Internship\\Literature\\SearchEq\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1f87c-6201-48ad-b4f4-2850e932712d",
   "metadata": {},
   "source": [
    "### 2. Introduce information of your search inquiry\n",
    "Copy the **exact name** of the **text** file (.txt) that includes the titles and abstracts of the search. Avoid using spaces and special characters in the names to prevent python malfunction. Using underscores ( _ ) is allowed. The text file can be easily created by copy-pasting the exported results of a search into a blocknote or into a word file and explicitly saving as .txt The order doesn't matter.\n",
    "\n",
    "Fill manually the number of records retrieved in the search. \n",
    "\n",
    "If you want, you can tune the treshold of the search to exclude more or less words. By default, I arbitrarily chose to remove words that appear on less than 5% of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d2362b-9873-45af-b9db-694f8ee85816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File to open:\n",
    "file=(r\"WoS2.txt\") #put the name inside the \"\", keep the r before the \"\".\n",
    "\n",
    "#Number of records retrieved \n",
    "N=341\n",
    "\n",
    "#Treshold (between 0.00 and 0.99)\n",
    "T=0.05\n",
    "\n",
    "if N > 100:\n",
    "    ninf=int(N*T)\n",
    "else:\n",
    "    ninf=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f9177-605d-4ec4-976d-3750d412b8d2",
   "metadata": {},
   "source": [
    "### 3. This is the functioning part\n",
    "The only thing you have to do here is delete or add the ```encoding=\"utf8\"``` function. If your text file is manually made, you don't need it. If the text file is retrieved directly from PubMed, it has to be included after the ```\"r\",```. \n",
    "\n",
    "You will find the frequency list as an output at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730498b8-f369-47a8-a268-08a50305a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=open(file,\"r\",encoding=\"utf8\").read() #when the txt file is retrieved from pubmed, encoding utf8 has to be explicitly shown here, otherwise is ok\n",
    "rmv = \",;:.\\n!\\\"')(][\" #removes any symbols by replacing them with spaces, don't include hyphens bc of IUPAC nomenclature\n",
    "for c in rmv:\n",
    "    txt = txt.replace(c,\"\") \n",
    "txt=txt.lower() #change all text into lowercase\n",
    "words=txt.split(\" \") #split words in each space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edad9bf2-ed14-4621-8cdb-497a2a70d05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvc  853\n",
      "dehp  660\n",
      "phthalate  389\n",
      "plasticizer  358\n",
      "plasticizers  270\n",
      "chloride  250\n",
      "polyvinyl  216\n",
      "extraction  211\n",
      "blood  206\n",
      "leaching  190\n",
      "plasticized  168\n",
      "exposure  157\n",
      "bags  150\n",
      "concentration  135\n",
      "migration  129\n",
      "materials  126\n",
      "acid  122\n",
      "medical  119\n",
      "stability  117\n",
      "properties  115\n",
      "thermal  111\n",
      "dop  108\n",
      "devices  106\n",
      "investigated  103\n",
      "compared  102\n",
      "temperature  98\n",
      "plastic  98\n",
      "found  96\n",
      "infusion  94\n",
      "solution  90\n",
      "phthalates  89\n",
      "degradation  89\n",
      "metabolites  88\n",
      "mechanical  85\n",
      "degrees  84\n",
      "surface  82\n",
      "chemical  81\n",
      "tubing  80\n",
      "range  79\n",
      "x  77\n",
      "effects  76\n",
      "effect  75\n",
      "additives  75\n",
      "resistance  71\n",
      "liquid  70\n",
      "human  69\n",
      "patients  69\n",
      "when  69\n",
      "studied  69\n",
      "+/-  68\n",
      "adsorption  68\n",
      "solvent  67\n",
      "storage  66\n",
      "mehp  66\n",
      "mg  66\n",
      "potential  64\n",
      "rate  64\n",
      "films  64\n",
      "solutions  63\n",
      "however  63\n",
      "dbp  63\n",
      "containing  63\n",
      "no  63\n",
      "significantly  63\n",
      "mass  62\n",
      "membrane  62\n",
      "polymer  61\n",
      "material  61\n",
      "urine  61\n",
      "could  59\n",
      "sets  58\n",
      "dioctyl  58\n",
      "content  57\n",
      "determined  56\n",
      "response  56\n",
      "elsevier  55\n",
      "leached  55\n",
      "prepared  55\n",
      "electrode  55\n",
      "well  54\n",
      "plasticizing  54\n",
      "h  53\n",
      "only  53\n",
      "flexible  52\n",
      "addition  52\n",
      "compounds  52\n",
      "increase  52\n",
      "groups  52\n",
      "oil  52\n",
      "mps  52\n",
      "detected  51\n",
      "drug  51\n",
      "out  50\n",
      "ester  50\n",
      "spectrometry  49\n",
      "1  49\n",
      "tensile  49\n",
      "had  48\n",
      "m  47\n",
      "plasma  47\n",
      "administration  47\n",
      "structure  47\n",
      "blends  47\n",
      "while  46\n",
      "rights  46\n",
      "bag  46\n",
      "indicated  46\n",
      "2  46\n",
      "loss  46\n",
      "nmr  46\n",
      "various  46\n",
      "synthesized  46\n",
      "characterized  46\n",
      "good  45\n",
      "10  45\n",
      "performance  45\n",
      "detection  45\n",
      "dinp  44\n",
      "esters  44\n",
      "chromatography  44\n",
      "tests  44\n",
      "toxicity  43\n",
      "evaluated  43\n",
      "there  43\n",
      "stored  41\n",
      "di2-ethylhexyl  41\n",
      "present  41\n",
      "determination  41\n",
      "up  41\n",
      "containers  41\n",
      "cell  41\n",
      "made  40\n",
      "developed  40\n",
      "alternative  40\n",
      "tubes  40\n",
      "urinary  40\n",
      "better  40\n",
      "compatibility  40\n",
      "molecular  40\n",
      "risk  39\n",
      "via  39\n",
      "red  39\n",
      "glass  39\n",
      "ph  39\n",
      "plastics  38\n",
      "performed  38\n",
      "days  38\n",
      "p  38\n",
      "measured  38\n",
      "without  38\n",
      "injection  38\n",
      "di-2-ethylhexyl  37\n",
      "production  37\n",
      "weight  37\n",
      "total  37\n",
      "exposed  37\n",
      "novel  37\n",
      "reduced  37\n",
      "should  37\n",
      "g/l  37\n",
      "limit  37\n",
      "cells  37\n",
      "excellent  37\n",
      "sensor  37\n",
      "order  36\n",
      "amounts  36\n",
      "release  36\n",
      "environmental  36\n",
      "sample  35\n",
      "reaction  35\n",
      "spectroscopy  35\n",
      "efficiency  35\n",
      "modified  35\n",
      "studies  34\n",
      "proposed  34\n",
      "times  34\n",
      "organic  34\n",
      "toxic  34\n",
      "increasing  34\n",
      "health  33\n",
      "contact  33\n",
      "g  33\n",
      "4  33\n",
      "group  33\n",
      "commercial  33\n",
      "5  32\n",
      ">  32\n",
      "possible  32\n",
      "behavior  32\n",
      "applied  32\n",
      "chemicals  32\n",
      "components  32\n",
      "exhibited  32\n",
      "pcl  32\n",
      "transition  32\n",
      "because  31\n",
      "matrix  31\n",
      "determine  31\n",
      "set  31\n",
      "level  31\n",
      "%  31\n",
      "improved  31\n",
      "analyzed  31\n",
      "solvents  31\n",
      "recovery  31\n",
      "strength  31\n",
      "bio-based  31\n",
      "system  30\n",
      "totm  30\n",
      "bv  30\n",
      "treatment  30\n",
      "associated  30\n",
      "decreased  30\n",
      "day  30\n",
      "tested  30\n",
      "iv  30\n",
      "paes  30\n",
      "influence  29\n",
      "dose  29\n",
      "h-1  29\n",
      "drugs  29\n",
      "initial  29\n",
      "work  29\n",
      "volatility  29\n",
      "application  29\n",
      "systems  29\n",
      "development  28\n",
      "some  28\n",
      "our  28\n",
      "-  28\n",
      "same  28\n",
      "<  28\n",
      "model  28\n",
      "main  28\n",
      "infants  28\n",
      "elimination  28\n",
      "break  28\n",
      "dynamic  28\n",
      "quantification  27\n",
      "dinch  27\n",
      "extracted  27\n",
      "widely  27\n",
      "effective  27\n",
      "tga  27\n",
      "24  27\n",
      "transfusion  27\n",
      "polyethylene  27\n",
      "children  27\n",
      "linear  27\n",
      "identified  27\n",
      "test  27\n",
      "metabolite  27\n",
      "diffusion  27\n",
      "sodium  27\n",
      "paclitaxel  27\n",
      "film  26\n",
      "environment  26\n",
      "patient  26\n",
      "20  26\n",
      "examined  26\n",
      "ether  26\n",
      "polymers  26\n",
      "elongation  26\n",
      "lines  26\n",
      "cardanol  26\n",
      "3  25\n",
      "30  25\n",
      "followed  25\n",
      "flexibility  25\n",
      "scanning  25\n",
      "released  25\n",
      "less  25\n",
      "derived  25\n",
      "waste  25\n",
      "ecmo  25\n",
      "epoxidized  25\n",
      "lipid  25\n",
      "pe  25\n",
      "added  24\n",
      "commonly  24\n",
      "aim  24\n",
      "uv  24\n",
      "l-1  24\n",
      "contained  24\n",
      "composition  24\n",
      "n  24\n",
      "5%  24\n",
      "infrared  24\n",
      "whereas  24\n",
      "collected  24\n",
      "even  24\n",
      "dibutyl  24\n",
      "plasticization  24\n",
      "ions  24\n",
      "electrodes  24\n",
      "research  23\n",
      "carried  23\n",
      "major  23\n",
      "gas  23\n",
      "very  23\n",
      "assessed  23\n",
      "demonstrated  23\n",
      "ranged  23\n",
      "control  23\n",
      "conclusion  23\n",
      "primary  23\n",
      "direct  23\n",
      "improve  23\n",
      "tube  23\n",
      "chains  23\n",
      "rbc  23\n",
      "alkyl  23\n",
      "simulated  23\n",
      "slope  23\n",
      "approach  22\n",
      "ratio  22\n",
      "care  22\n",
      "trimellitate  22\n",
      "50  22\n",
      "they  22\n",
      "platelet  22\n",
      "decrease  22\n",
      "produced  22\n",
      "species  22\n",
      "interaction  22\n",
      "dialysis  21\n",
      "exposures  21\n",
      "many  21\n",
      "substitution  21\n",
      "analyses  21\n",
      "degree  21\n",
      "available  21\n",
      "reduce  21\n",
      "corresponding  21\n",
      "evaluate  21\n",
      "measurements  21\n",
      "furthermore  21\n",
      "replace  21\n",
      "processes  21\n",
      "preparation  21\n",
      "revealed  21\n",
      "polyvinylchloride  21\n",
      "ftir  21\n",
      "reduction  21\n",
      "polyolefin  21\n",
      "humans  20\n",
      "risks  20\n",
      "high-performance  20\n",
      "show  20\n",
      "6  20\n",
      "25  20\n",
      "endocrine  20\n",
      "contamination  20\n",
      "selectivity  20\n",
      "attention  20\n",
      "confirmed  20\n",
      "maximum  20\n",
      "either  20\n",
      "experiments  20\n",
      "resulting  20\n",
      "stable  20\n",
      "single  20\n",
      "molecules  20\n",
      "traditional  20\n",
      "pharmaceutical  20\n",
      "conventional  20\n",
      "chain  20\n",
      "activation  20\n",
      "changes  20\n",
      "plastisols  20\n",
      "mol  20\n",
      "reproductive  19\n",
      "mechanism  19\n",
      "internal  19\n",
      "raw  19\n",
      "best  19\n",
      "applications  19\n",
      "leach  19\n",
      "phase  19\n",
      "dphp  19\n",
      "tehtm  19\n",
      "comparison  19\n",
      "fourier  19\n",
      "activity  19\n",
      "comparable  19\n",
      "extracts  19\n",
      "design  19\n",
      "intravenous  19\n",
      "pressure  19\n",
      "40  19\n",
      "product  19\n",
      "efficient  19\n",
      "period  19\n",
      "series  19\n",
      "months  19\n",
      "reached  19\n",
      "methyl  19\n",
      "interactions  19\n",
      "sorption  19\n",
      "tpn  19\n",
      "hours  19\n",
      "k  19\n",
      "electron  18\n",
      "impact  18\n",
      "moreover  18\n",
      "gc-ms  18\n",
      "coupled  18\n",
      "where  18\n",
      "coating  18\n",
      "known  18\n",
      "intensive  18\n",
      "terephthalate  18\n",
      "presented  18\n",
      "like  18\n",
      "acetate  18\n",
      "simple  18\n",
      "min  18\n",
      "transform  18\n",
      "removal  18\n",
      "techniques  18\n",
      "quantified  18\n",
      "paper  18\n",
      "quantitative  18\n",
      "&  18\n",
      "i  18\n",
      "additive  18\n",
      "09%  18\n",
      "achieved  18\n",
      "coated  18\n",
      "value  18\n",
      "industry  18\n",
      "energy  18\n",
      "ion  18\n",
      "particles  18\n",
      "synthesis  18\n",
      "fatty  18\n",
      "hcl  18\n",
      "t-g  18\n",
      "potentiometric  18\n"
     ]
    }
   ],
   "source": [
    "Dict = {} #create an empty dictionary to fill it with the words in the abstracts\n",
    "for w in words: #fills the dictionary with the words in the abstracts and counts the frequency \n",
    "    if w in Dict:\n",
    "        Dict[w] += 1\n",
    "    else:\n",
    "        Dict[w] = 1\n",
    "\n",
    "exclude=[\n",
    "    'the', 'of', 'and', 'in', 'to', 'a', 'with', 'for', 'or', 'been', \n",
    "    'use', 'which', 'c', 'during', 'into', 'samples', 'their', 'results', \n",
    "    'have', 'levels', 'concentrations', 'all', 'not', 'mu', 'products', \n",
    "    'were', 'was', 'is', 'its', 'as', 'are', 'that', 'it', 'from', 'such', \n",
    "    'study', 'on', 'this', 'using', 'may', 'be', 'by', 'used', 'we', 'an', \n",
    "    'these', 'at', 'on', 'data', 'analysis', 'based', 'methods', 'method', \n",
    "    'one', 'two', 'three', 'four', 'five', 'between', 'after', 'before', \n",
    "    'process', 'than', 'values', 'parameter', 'parameters', 'can', \n",
    "    'different', 'other', 'more', 'number', 'including', 'shown', 'example', \n",
    "    'time', 'each', 'several', 'about', 'according', 'although', 'thus', \n",
    "    'therefore', 'those', 'due', 'both', 'first', 'second', 'third', 'if', \n",
    "    'then', 'under', 'over', 'through', 'any', 'important', 'observed', \n",
    "    'indicate', 'observations', 'respectively', 'obtained', 'shown', \n",
    "    'relative', 'presence', 'absence', 'type', 'types', 'mean', 'average', \n",
    "    'conditions', 'condition', 'small', 'large', 'high', 'low', 'among', \n",
    "    'further', 'within', 'per', 'units', 'during', 'recent', 'new', 'most', \n",
    "    'amount', 'common', 'specific', 'similar', 'highly', 'strong', 'weak', \n",
    "    'higher', 'lower', 'standard', 'deviation', 'significant', 'significance'\n",
    "    'studies','but','has','increased','also','showed','=','university','doi','indexed'\n",
    "]\n",
    "CleanDict={k:v for k,v in Dict.items() if k not in exclude} #removes the stopwords from the dictionary \n",
    "\n",
    "#sorts the dictionary from higher to lower values\n",
    "CleanDict={key: val for key, val in sorted(CleanDict.items(), key = lambda ele: ele[1],reverse=True)}\n",
    "\n",
    "for w in CleanDict:\n",
    "    if CleanDict[w] > ninf: #Compares the frequency with the treshold\n",
    "        print(f\"{w}  {CleanDict[w]}\") #This prints the frequency list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a8c400-69a3-421a-9ee6-bed52cc0f8e3",
   "metadata": {},
   "source": [
    "### Export it as an Excel file\n",
    "If you want to export the frequency list into excel, run the code below. The new file will appear in the same location as the original file. Python **will not tell you** if the documents are being overwritten so be careful to export it with a unique name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82267018-bf87-4f2b-b4a4-7799d1fb02fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {key: val for key, val in CleanDict.items() if val > ninf}\n",
    "df = pd.DataFrame(list(d.items()), columns=['Word', 'Frequency'])\n",
    "\n",
    "df.to_excel(\"example1.xlsx\", index=False) #write the name here\n",
    "print(\"Exported\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
